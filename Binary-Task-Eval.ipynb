{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#tqdm is for progress bar functionality in code, must be installed for code to function\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Importing libraries used for SVM classification and model assessment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "#Libraries for CNN model\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#Importing functions notebook containing functions created to streamline code\n",
    "from ipynb.fs.full.functions import load_dataset, dataset_PCA, Tuned_SVM_train, SVM_predictions, load_dataset_CNN, image_array_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Trained Binary Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Untuned SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Untuned SVM model from disk\n"
     ]
    }
   ],
   "source": [
    "#Code to load of trained tuned SVM model\n",
    "untuned_SVM = pkl.load(open('.\\\\Models\\\\Binary-Classification\\\\Untuned_SVM_model.sav', 'rb'))\n",
    "print(\"Loaded Untuned SVM model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Tuned SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Tuned SVM model from disk\n",
      "With Parameters:  {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "#Code to test loading of trained tuned SVM model\n",
    "Tuned_SVM = pkl.load(open('.\\\\Models\\\\Binary-Classification\\\\Tuned_SVM_model.sav', 'rb'))\n",
    "print(\"Loaded Tuned SVM model from disk\")\n",
    "\n",
    "#Gets the best parameter values from loaded model\n",
    "best_param = Tuned_SVM.best_params_\n",
    "#Prints out the parameter values\n",
    "#Output should match earlier .best_params_ output\n",
    "print(\"With Parameters: \", best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CNN model from disk\n"
     ]
    }
   ],
   "source": [
    "# load Binary CNN json and create model\n",
    "json_file = open(\".\\\\Models\\\\Binary-Classification\\\\CNN\\\\Binary_CNN.json\", 'r')\n",
    "binary_model_json = json_file.read()\n",
    "json_file.close()\n",
    "binary_CNN = model_from_json(binary_model_json)\n",
    "# load weights into new model\n",
    "binary_CNN.load_weights(\".\\\\Models\\\\Binary-Classification\\\\CNN\\\\Binary_CNN_Model_Weights\")\n",
    "print(\"Loaded CNN model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading extra test dataset and carrying out necessary preprocessing\n",
    "#### 2.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 503.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted original Images from dataset!\n",
      "(200, 20, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#We set the path to the images in the dataset folder\n",
    "#Image will be resized to 28 * 28\n",
    "SVM_Images = image_array_resize('dataset\\Extra_test_dataset\\image',20)\n",
    "print(SVM_Images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 400)\n"
     ]
    }
   ],
   "source": [
    "#Reshapes the 3D array into 2D \n",
    "#This is because PCA only accepts 2D array inputs\n",
    "SVM_flattened = SVM_Images.reshape(200, (20 * 20))\n",
    "print(SVM_flattened.shape)\n",
    "#resultant array is 3000 * 784 with all 784 pixels arranged in a single row instead of 28 * 28\n",
    "SVM_flattened_scaled = SVM_flattened/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 168/200 [00:00<00:00, 837.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:00<00:00, 855.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully extracted original Images from dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Do the same for our CNN images resized to 50\n",
    "CNN_Images = image_array_resize('dataset\\Extra_test_dataset\\image',50)\n",
    "\n",
    "#Adding 4th channel to array (for convnet fitting)\n",
    "#The last channel is indicating whether it is a RGB channel (3) or grayscale (1) image\n",
    "CNN_Images_4D = CNN_Images.reshape(200,50,50,1)\n",
    "\n",
    "#Getting our Y and X inputs for the model and scaling the X inputs\n",
    "#Carrying out scaling of the pixel data per element so that it is between 0 and 1\n",
    "xTest_CNN = CNN_Images_4D/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Loading Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yTest Label array setup!\n"
     ]
    }
   ],
   "source": [
    "#Loading the CSV Label file\n",
    "extra_test_labels = pd.read_csv('./dataset/Extra_test_dataset/label.csv')\n",
    "\n",
    "#Taking just the label portion for editing into our Target Y array\n",
    "Y = extra_test_labels[['label']]\n",
    "Y_np = Y.to_numpy()\n",
    "\n",
    "\n",
    "#For loop through the number of elements in the label dataset, in this case 3000\n",
    "#Loop will check if the array element is == to no_tumor in a string compare condition.\n",
    "#If it returns true, that means the element is labelling no_tumor and therefore we set the corresponding element value of the Y_binary array to 0\n",
    "#Therefore if the output of the compare returns false, regardless of the type of tumor we set the element value to = 1\n",
    "#Meaning the target label is showing a tumor in the mri image.\n",
    "\n",
    "#Initialises empty array for Y data for binary task\n",
    "yTest = np.zeros(len(Y_np))\n",
    "\n",
    "for x in range(len(Y_np)):\n",
    "\n",
    "    if Y_np[x] == 'no_tumor':\n",
    "        yTest[x] = 0\n",
    "    else:\n",
    "        yTest[x] = 1\n",
    "\n",
    "print(\"yTest Label array setup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predictions on extra test Dataset\n",
    "##### This section shows the additional predictions done on an out of sample dataset released one week before the deadline for optional testing of models and prints out the classification report, confusion matrix and other metrics for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 400)\n"
     ]
    }
   ],
   "source": [
    "print(SVM_flattened_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Results for SVM are:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        37\n",
      "         1.0       0.81      1.00      0.90       163\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.41      0.50      0.45       200\n",
      "weighted avg       0.66      0.81      0.73       200\n",
      "\n",
      "The confusion matrix is:\n",
      "[[  0  37]\n",
      " [  0 163]]\n",
      "The Results for SVM are:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.20      0.92      0.33        37\n",
      "         1.0       0.91      0.18      0.30       163\n",
      "\n",
      "    accuracy                           0.32       200\n",
      "   macro avg       0.55      0.55      0.31       200\n",
      "weighted avg       0.78      0.32      0.30       200\n",
      "\n",
      "The confusion matrix is:\n",
      "[[ 34   3]\n",
      " [134  29]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\gym\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda\\envs\\gym\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Anaconda\\envs\\gym\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Calls SVM_predictions function from \"functions.ipynb\"\n",
    "#This time we are doing predictions with the untuned SVM model\n",
    "untuned_SVM_pred = SVM_predictions(untuned_SVM, SVM_flattened_scaled, yTest)\n",
    "\n",
    "#This time we are doing predictions with the tuned SVM model\n",
    "Tuned_SVM_pred = SVM_predictions(Tuned_SVM, SVM_flattened_scaled, yTest)\n",
    "\n",
    "#It prints out the classification report of the predictions as well as the confusion matrix\n",
    "#Returns the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 11s 54ms/step\n",
      "The Results for Binary CNN are:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.76      0.81        37\n",
      "         1.0       0.95      0.98      0.96       163\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.91      0.87      0.89       200\n",
      "weighted avg       0.93      0.94      0.93       200\n",
      "\n",
      "The confusion matrix is:\n",
      "[[ 28   9]\n",
      " [  4 159]]\n"
     ]
    }
   ],
   "source": [
    "#Making Predictions with the model\n",
    "Binary_CNN_pred = binary_CNN.predict_classes(xTest_CNN, verbose = 1)\n",
    "\n",
    "#Printing the classification report and metrics\n",
    "print(\"The Results for Binary CNN are:\")\n",
    "print(classification_report(yTest, Binary_CNN_pred))\n",
    "\n",
    "#Printing the confusion matrix for Binary CNN\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(yTest, Binary_CNN_pred))\n",
    "\n",
    "#To obtain TNR, TPR and FPR metrics for Binary CNN in discrete form\n",
    "FPR_Binary_CNN, TPR_Binary_CNN, Binary_CNN_thres = roc_curve(yTest, Binary_CNN_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "290ec9070849e8daf2fe4bd922bd966932468e9fb905fb4b926b0f4d9e51cc32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('gym': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
