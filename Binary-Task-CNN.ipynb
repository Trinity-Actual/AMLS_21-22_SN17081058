{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Task CNN Notebook\n",
    "\n",
    "### Contains Code for Binary task CNN Model creation, training and testing<br/> CNN will be an implementation of AlexNet equivalent structure 5 convolutional layers and 3 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#tqdm is for progress bar functionality in code, must be installed for code to function (TO DO: include exception if tqdm not imported )\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "\n",
    "#Libraries for CNN model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Labels and Resized Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading created pkl files for binary labels and image data.\n",
    "Binary_labels = pd.read_pickle('./dataset/Y_Binary_label.pkl')\n",
    "MRI_2D_imgs = pd.read_pickle('./dataset/CNN_Images_2D_DF.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 193\n"
     ]
    }
   ],
   "source": [
    "MRI_2D_img_array = np.array(MRI_2D_imgs)\n",
    "MRI_img_array = MRI_2D_img_array.reshape(MRI_2D_img_array.shape[0],50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50, 50)\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 212\n"
     ]
    }
   ],
   "source": [
    "print(MRI_img_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding 4th channel to array (for convnet fitting)\n",
    "#The last channel is\n",
    "MRI_img_array_channel = MRI_img_array.reshape(3000,50,50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(MRI_img_array_channel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our Y and X inputs for the model and scaling the X inputs\n",
    "Y = Binary_labels[['MRI_Binary_Label']]\n",
    "\n",
    "X = MRI_img_array_channel/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing(70% training and 30% testing data)\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(X, Y, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Binary_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 13, 13, 24)        2928      \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 13, 13, 24)        96        \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 13, 13, 24)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 7, 7, 24)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 7, 7, 64)          38464     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 4, 4, 96)          55392     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 4, 4, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 96)          83040     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 4, 96)          384       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 4, 4, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 4, 4, 64)          55360     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 2500)              642500    \n",
      "_________________________________________________________________\n",
      "bnfc0 (BatchNormalization)   (None, 2500)              10000     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2500)              6252500   \n",
      "_________________________________________________________________\n",
      "bnfc1 (BatchNormalization)   (None, 2500)              10000     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 500)               1250500   \n",
      "_________________________________________________________________\n",
      "bnfc2 (BatchNormalization)   (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "fcOut (Dense)                (None, 1)                 501       \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,404,565\n",
      "Trainable params: 8,392,875\n",
      "Non-trainable params: 11,690\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Initialising the Model\n",
    "Binary_CNN = Sequential(name = 'Binary_CNN')\n",
    "\n",
    "#We use a smaller number of filters compared to original Alexnet implementation\n",
    "#Testing computational power first\n",
    "#Original Filter numbers/4 so:\n",
    "#24 64 96 96 64\n",
    "\n",
    "#1st Convolutional Layer\n",
    "#Input arguements\n",
    "#Filters: Number of output filters in convolution\n",
    "Binary_CNN.add(Conv2D(filters = 24, input_shape = (MRI_img_array.shape[1], MRI_img_array.shape[2], 1), kernel_size = (11, 11), strides = (4, 4), padding = 'same', name=\"conv0\"))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bn0'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "Binary_CNN.add(Conv2D(filters = 64, kernel_size = (5, 5), strides = (1, 1), padding = 'same', name=\"conv1\"))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bn1'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "Binary_CNN.add(Conv2D(filters = 96, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv2\"))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bn2'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#4th Convolutional Layer\n",
    "Binary_CNN.add(Conv2D(filters = 96, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv3\"))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bn3'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#5th Convolutional Layer\n",
    "Binary_CNN.add(Conv2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv4\"))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bn4'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#Passing through the Fully connected layers\n",
    "#We set the number of neurons per layer as 2500 for now\n",
    "#Less than orignal 4096\n",
    "Binary_CNN.add(Flatten())\n",
    "\n",
    "#1st Fully Connected Layer\n",
    "Binary_CNN.add(Dense(2500, name = 'fc0'))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bnfc0'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "Binary_CNN.add(Dense(2500, name = 'fc1'))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bnfc1'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "Binary_CNN.add(Dense(500, name = 'fc2'))\n",
    "Binary_CNN.add(BatchNormalization(name = 'bnfc2'))\n",
    "Binary_CNN.add(Activation('relu'))\n",
    "Binary_CNN.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "#Output Layer\n",
    "Binary_CNN.add(Dense(1, name = 'fcOut'))\n",
    "Binary_CNN.add(BatchNormalization())\n",
    "Binary_CNN.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "Binary_CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "Binary_CNN.compile(loss='binary_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_Model():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 203\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up training and testing data generators for image inputs\n",
    "xTrain_imggen = ImageDataGenerator(rescale = 1./255)\n",
    "xTest_imggen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "#Setting up generator from our image array xTrain and xTest\n",
    "xTrain_generator = xTrain_imggen.flow(xTrain, batch_size = 50)\n",
    "\n",
    "\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#tensorboard = TensorBoard(log_dir=\"./logs/Binary_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate Annealer\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "lrr = ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining model training parameters\n",
    "batch_size = 50\n",
    "epochs = 10\n",
    "learn_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 19s - loss: 0.6121 - accuracy: 0.7767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\gym\\lib\\site-packages\\keras\\callbacks\\callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      " - 2s - loss: 0.5072 - accuracy: 0.8838\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.4510 - accuracy: 0.9424\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.4284 - accuracy: 0.9552\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.3990 - accuracy: 0.9633\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.3796 - accuracy: 0.9724\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.3610 - accuracy: 0.9781\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.3387 - accuracy: 0.9867\n",
      "Epoch 9/10\n",
      " - 2s - loss: 0.3214 - accuracy: 0.9871\n",
      "Epoch 10/10\n",
      " - 2s - loss: 0.3120 - accuracy: 0.9876\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "History = Binary_CNN.fit(xTrain, yTrain, batch_size= batch_size, epochs= epochs, verbose = 2, callbacks = [lrr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'lr'])\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 214\n"
     ]
    }
   ],
   "source": [
    "print(History.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.98761904\n",
      "Training loss:  0.3120093721719015\n"
     ]
    }
   ],
   "source": [
    "acc = History.history['accuracy'][-1]\n",
    "loss = History.history['loss'][-1]\n",
    "\n",
    "\n",
    "print(\"Training accuracy: \", acc)\n",
    "print(\"Training loss: \", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = range(1, len(History.history['accuracy'])+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "290ec9070849e8daf2fe4bd922bd966932468e9fb905fb4b926b0f4d9e51cc32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('gym': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
