{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Task CNN Notebook\n",
    "\n",
    "### Contains Code for Multiclass task CNN Model creation, training and testing<br/> CNN will be an implementation of AlexNet equivalent structure 5 convolutional layers and 3 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#tqdm is for progress bar functionality in code, must be installed for code to function (TO DO: include exception if tqdm not imported )\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle as pkl\n",
    "import cv2\n",
    "\n",
    "#Libraries for CNN model\n",
    "from keras import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import model_from_json\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Importing functions notebook containing functions created to streamline code\n",
    "from ipynb.fs.full.functions import load_dataset_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Labels and Resized Image Dataset\n",
    "### 1.1 Loading Dataset via load_dataset_CNN function in \"function.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets successfully loaded with shapes:\n",
      "X Shape:\n",
      "(3000, 50, 50, 1)\n",
      "Y Shape:\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "#Calls load_dataset_CNN function from function.ipynb to obtain the MRI images dataset and the Multiclass label pickle file and loads it respectively \n",
    "#into our X and Y value. Function also conducts rescaling of image pixel data from 0 to 255 to 0 to 1 range.\n",
    "X, Y = load_dataset_CNN('./dataset/CNN_Images_2D_DF.pkl', './dataset/Y_Multiclass_Label.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Making Multiclass target labels into \"one-hot\" Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Splitting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing(70% training and 30% testing data)\n",
    "# Setting random_state to 42 keeps the same random generator seed to be used.\n",
    "# This maintains the split used across code executions so results obtained will be the same for other users\n",
    "xTrain,xTest,yTrain,yTest=train_test_split(X, Y, train_size = 0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Displaying label distribution<br/> We show the the number of samples in each class label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset number of samples per class:\n",
      "1.0    603\n",
      "2.0    591\n",
      "3.0    586\n",
      "0.0    320\n",
      "Name: MRI_Multiclass_Label, dtype: int64\n",
      "Test dataset number of samples per class:\n",
      "2.0    264\n",
      "1.0    257\n",
      "3.0    245\n",
      "0.0    134\n",
      "Name: MRI_Multiclass_Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Number of Samples per class in training data\n",
    "print(\"Training dataset number of samples per class:\")\n",
    "print(yTrain.value_counts())\n",
    "\n",
    "#Number of Samples per class in test data\n",
    "print(\"Test dataset number of samples per class:\")\n",
    "print(yTest.value_counts())\n",
    "\n",
    "#These values should match the number of samples in the multiclass SVM train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 4)\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Before we proceed to model building we need to reconfigure the training set labels array into \n",
    "# categories or \"one-hot\" encoding for the multiclass CNN outputs\n",
    "yTrain_OneHot = to_categorical(yTrain)\n",
    "\n",
    "#Verifies new shape of target label array to be a 2100 by 4 matrix\n",
    "print(yTrain_OneHot.shape)\n",
    "print(yTrain_OneHot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Multiclass_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv0 (Conv2D)               (None, 13, 13, 96)        11712     \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 13, 13, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 96)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 7, 7, 256)         614656    \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 7, 7, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 4, 4, 384)         885120    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 4, 4, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 4, 4, 256)         884992    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc0 (Dense)                  (None, 2500)              2562500   \n",
      "_________________________________________________________________\n",
      "bnfc0 (BatchNormalization)   (None, 2500)              10000     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 2500)              6252500   \n",
      "_________________________________________________________________\n",
      "bnfc1 (BatchNormalization)   (None, 2500)              10000     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2500)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 500)               1250500   \n",
      "_________________________________________________________________\n",
      "bnfc2 (BatchNormalization)   (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "fcOut (Dense)                (None, 4)                 2004      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 13,818,992\n",
      "Trainable params: 13,805,232\n",
      "Non-trainable params: 13,760\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Initialising the Model\n",
    "Multiclass_CNN = Sequential(name = 'Multiclass_CNN')\n",
    "\n",
    "#We use the same number of filters in all convolutional layers of the AlexNet Model\n",
    "#Number of filters in the fully connected layers will be reduced to 2500 2500 and 500\n",
    "#This is to reduce size of CNN so it can be fit into Github without LFS\n",
    "# Final output layer will have 4 nodes which corresponds to the 4 target labels in the MRI image dataset\n",
    "\n",
    "#1st Convolutional Layer\n",
    "#Input arguements\n",
    "#Filters: Number of output filters in convolution\n",
    "Multiclass_CNN.add(Conv2D(filters = 96, input_shape = (X.shape[1], X.shape[2], 1), kernel_size = (11, 11), strides = (4, 4), padding = 'same', name=\"conv0\"))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bn0'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "Multiclass_CNN.add(Conv2D(filters = 256, kernel_size = (5, 5), strides = (1, 1), padding = 'same', name=\"conv1\"))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bn1'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "Multiclass_CNN.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv2\"))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bn2'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#4th Convolutional Layer\n",
    "Multiclass_CNN.add(Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv3\"))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bn3'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#5th Convolutional Layer\n",
    "Multiclass_CNN.add(Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', name=\"conv4\"))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bn4'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
    "\n",
    "\n",
    "#Passing through the Fully connected layers\n",
    "#We set the number of neurons per layer as 2500 for now\n",
    "#Less than orignal 4096\n",
    "Multiclass_CNN.add(Flatten())\n",
    "\n",
    "#1st Fully Connected Layer\n",
    "Multiclass_CNN.add(Dense(2500, name = 'fc0'))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bnfc0'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(Dropout(0.4))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "Multiclass_CNN.add(Dense(2500, name = 'fc1'))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bnfc1'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(Dropout(0.4))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "Multiclass_CNN.add(Dense(500, name = 'fc2'))\n",
    "Multiclass_CNN.add(BatchNormalization(name = 'bnfc2'))\n",
    "Multiclass_CNN.add(Activation('relu'))\n",
    "Multiclass_CNN.add(Dropout(0.4))\n",
    "\n",
    "\n",
    "#Output Layer\n",
    "Multiclass_CNN.add(Dense(4, name = 'fcOut'))\n",
    "Multiclass_CNN.add(BatchNormalization())\n",
    "Multiclass_CNN.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "Multiclass_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compiling Multiclass CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "#Loss function is categorical_crossentropy\n",
    "#Optimizer is Adam \n",
    "#Metrics to be observed are\n",
    "# Accuracy (both training and validation)\n",
    "# Categorical Accuracy\n",
    "# Categorical Crossentropy\n",
    "# AUC metric\n",
    "Multiclass_CNN.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy', metrics.CategoricalAccuracy(), metrics.CategoricalCrossentropy(), metrics.AUC()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model Training\n",
    "#### 2.3.1 Defining model training callbacks and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning Rate callback\n",
    "lrr= ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.01, patience = 3, min_lr = 1e-5) \n",
    "\n",
    "\n",
    "#Earlystopping callback\n",
    "#This will end the training before the final defined epoch if the validation loss plateaus for more than 5 epochs\n",
    "#Validation loss is the metric which the callback is monitoring\n",
    "ES = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
    "\n",
    "#Defining model training parameters\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "learn_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Training Model with validation set derived from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1470 samples, validate on 630 samples\n",
      "Epoch 1/30\n",
      "1470/1470 [==============================] - 10s 7ms/step - loss: 1.0693 - accuracy: 0.5490 - categorical_accuracy: 0.5490 - categorical_crossentropy: 1.0693 - auc_4: 0.8047 - val_loss: 2.0904 - val_accuracy: 0.3000 - val_categorical_accuracy: 0.3000 - val_categorical_crossentropy: 2.0904 - val_auc_4: 0.5669\n",
      "Epoch 2/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.9083 - accuracy: 0.6381 - categorical_accuracy: 0.6381 - categorical_crossentropy: 0.9083 - auc_4: 0.8633 - val_loss: 2.4712 - val_accuracy: 0.2968 - val_categorical_accuracy: 0.2968 - val_categorical_crossentropy: 2.4712 - val_auc_4: 0.5390\n",
      "Epoch 3/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.7522 - accuracy: 0.7218 - categorical_accuracy: 0.7218 - categorical_crossentropy: 0.7522 - auc_4: 0.9158 - val_loss: 1.6886 - val_accuracy: 0.3635 - val_categorical_accuracy: 0.3635 - val_categorical_crossentropy: 1.6886 - val_auc_4: 0.5477\n",
      "Epoch 4/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.6407 - accuracy: 0.7912 - categorical_accuracy: 0.7912 - categorical_crossentropy: 0.6407 - auc_4: 0.9406 - val_loss: 2.5198 - val_accuracy: 0.1492 - val_categorical_accuracy: 0.1492 - val_categorical_crossentropy: 2.5198 - val_auc_4: 0.4993\n",
      "Epoch 5/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.5641 - accuracy: 0.8272 - categorical_accuracy: 0.8272 - categorical_crossentropy: 0.5641 - auc_4: 0.9566 - val_loss: 2.4967 - val_accuracy: 0.1460 - val_categorical_accuracy: 0.1460 - val_categorical_crossentropy: 2.4967 - val_auc_4: 0.5400\n",
      "Epoch 6/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.4604 - accuracy: 0.8857 - categorical_accuracy: 0.8857 - categorical_crossentropy: 0.4604 - auc_4: 0.9740 - val_loss: 2.7413 - val_accuracy: 0.1460 - val_categorical_accuracy: 0.1460 - val_categorical_crossentropy: 2.7413 - val_auc_4: 0.5621\n",
      "Epoch 7/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.3924 - accuracy: 0.9068 - categorical_accuracy: 0.9068 - categorical_crossentropy: 0.3924 - auc_4: 0.9871 - val_loss: 1.5854 - val_accuracy: 0.3016 - val_categorical_accuracy: 0.3016 - val_categorical_crossentropy: 1.5854 - val_auc_4: 0.5981\n",
      "Epoch 8/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.3515 - accuracy: 0.9374 - categorical_accuracy: 0.9374 - categorical_crossentropy: 0.3515 - auc_4: 0.9915 - val_loss: 1.3020 - val_accuracy: 0.5460 - val_categorical_accuracy: 0.5460 - val_categorical_crossentropy: 1.3020 - val_auc_4: 0.7038\n",
      "Epoch 9/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.3506 - accuracy: 0.9401 - categorical_accuracy: 0.9401 - categorical_crossentropy: 0.3506 - auc_4: 0.9927 - val_loss: 1.1722 - val_accuracy: 0.6206 - val_categorical_accuracy: 0.6206 - val_categorical_crossentropy: 1.1722 - val_auc_4: 0.7465\n",
      "Epoch 10/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.3350 - accuracy: 0.9524 - categorical_accuracy: 0.9524 - categorical_crossentropy: 0.3350 - auc_4: 0.9941 - val_loss: 1.0702 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444 - val_categorical_crossentropy: 1.0702 - val_auc_4: 0.7870\n",
      "Epoch 11/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.3169 - accuracy: 0.9619 - categorical_accuracy: 0.9619 - categorical_crossentropy: 0.3169 - auc_4: 0.9955 - val_loss: 0.9655 - val_accuracy: 0.6635 - val_categorical_accuracy: 0.6635 - val_categorical_crossentropy: 0.9655 - val_auc_4: 0.8320\n",
      "Epoch 12/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.3142 - accuracy: 0.9599 - categorical_accuracy: 0.9599 - categorical_crossentropy: 0.3142 - auc_4: 0.9958 - val_loss: 0.8618 - val_accuracy: 0.6905 - val_categorical_accuracy: 0.6905 - val_categorical_crossentropy: 0.8618 - val_auc_4: 0.8703\n",
      "Epoch 13/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.3126 - accuracy: 0.9639 - categorical_accuracy: 0.9639 - categorical_crossentropy: 0.3126 - auc_4: 0.9961 - val_loss: 0.7548 - val_accuracy: 0.7444 - val_categorical_accuracy: 0.7444 - val_categorical_crossentropy: 0.7548 - val_auc_4: 0.9023\n",
      "Epoch 14/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.3249 - accuracy: 0.9537 - categorical_accuracy: 0.9537 - categorical_crossentropy: 0.3249 - auc_4: 0.9939 - val_loss: 0.6646 - val_accuracy: 0.7905 - val_categorical_accuracy: 0.7905 - val_categorical_crossentropy: 0.6646 - val_auc_4: 0.9287\n",
      "Epoch 15/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.9653 - categorical_accuracy: 0.9653 - categorical_crossentropy: 0.3074 - auc_4: 0.9964 - val_loss: 0.6086 - val_accuracy: 0.8159 - val_categorical_accuracy: 0.8159 - val_categorical_crossentropy: 0.6086 - val_auc_4: 0.9445 - categorical_accuracy: 0.9700 - catego\n",
      "Epoch 16/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.3081 - accuracy: 0.9646 - categorical_accuracy: 0.9646 - categorical_crossentropy: 0.3081 - auc_4: 0.9958 - val_loss: 0.5874 - val_accuracy: 0.8159 - val_categorical_accuracy: 0.8159 - val_categorical_crossentropy: 0.5874 - val_auc_4: 0.9503\n",
      "Epoch 17/30\n",
      "1470/1470 [==============================] - 4s 3ms/step - loss: 0.2998 - accuracy: 0.9680 - categorical_accuracy: 0.9680 - categorical_crossentropy: 0.2998 - auc_4: 0.9970 - val_loss: 0.5643 - val_accuracy: 0.8238 - val_categorical_accuracy: 0.8238 - val_categorical_crossentropy: 0.5643 - val_auc_4: 0.9567\n",
      "Epoch 18/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2987 - accuracy: 0.9687 - categorical_accuracy: 0.9687 - categorical_crossentropy: 0.2987 - auc_4: 0.9973 - val_loss: 0.5642 - val_accuracy: 0.8254 - val_categorical_accuracy: 0.8254 - val_categorical_crossentropy: 0.5642 - val_auc_4: 0.9566\n",
      "Epoch 19/30\n",
      "1470/1470 [==============================] - 4s 2ms/step - loss: 0.2961 - accuracy: 0.9673 - categorical_accuracy: 0.9673 - categorical_crossentropy: 0.2961 - auc_4: 0.9966 - val_loss: 0.5594 - val_accuracy: 0.8206 - val_categorical_accuracy: 0.8206 - val_categorical_crossentropy: 0.5594 - val_auc_4: 0.9577\n",
      "Epoch 20/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.3047 - accuracy: 0.9646 - categorical_accuracy: 0.9646 - categorical_crossentropy: 0.3047 - auc_4: 0.9951 - val_loss: 0.5560 - val_accuracy: 0.8206 - val_categorical_accuracy: 0.8206 - val_categorical_crossentropy: 0.5560 - val_auc_4: 0.9591\n",
      "Epoch 21/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2803 - accuracy: 0.9748 - categorical_accuracy: 0.9748 - categorical_crossentropy: 0.2803 - auc_4: 0.9982 - val_loss: 0.5511 - val_accuracy: 0.8206 - val_categorical_accuracy: 0.8206 - val_categorical_crossentropy: 0.5511 - val_auc_4: 0.9610\n",
      "Epoch 22/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2866 - accuracy: 0.9755 - categorical_accuracy: 0.9755 - categorical_crossentropy: 0.2866 - auc_4: 0.9979 - val_loss: 0.5504 - val_accuracy: 0.8190 - val_categorical_accuracy: 0.8190 - val_categorical_crossentropy: 0.5504 - val_auc_4: 0.9611\n",
      "Epoch 23/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2861 - accuracy: 0.9741 - categorical_accuracy: 0.9741 - categorical_crossentropy: 0.2861 - auc_4: 0.9975 - val_loss: 0.5604 - val_accuracy: 0.8333 - val_categorical_accuracy: 0.8333 - val_categorical_crossentropy: 0.5604 - val_auc_4: 0.9592\n",
      "Epoch 24/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2796 - accuracy: 0.9741 - categorical_accuracy: 0.9741 - categorical_crossentropy: 0.2796 - auc_4: 0.9979 - val_loss: 0.5521 - val_accuracy: 0.8190 - val_categorical_accuracy: 0.8190 - val_categorical_crossentropy: 0.5521 - val_auc_4: 0.9616\n",
      "Epoch 25/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2729 - accuracy: 0.9776 - categorical_accuracy: 0.9776 - categorical_crossentropy: 0.2729 - auc_4: 0.9982 - val_loss: 0.5503 - val_accuracy: 0.8270 - val_categorical_accuracy: 0.8270 - val_categorical_crossentropy: 0.5503 - val_auc_4: 0.9625 - categorical_accuracy: 0.9826 - categorica\n",
      "Epoch 26/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2805 - accuracy: 0.9748 - categorical_accuracy: 0.9748 - categorical_crossentropy: 0.2805 - auc_4: 0.9981 - val_loss: 0.5508 - val_accuracy: 0.8206 - val_categorical_accuracy: 0.8206 - val_categorical_crossentropy: 0.5508 - val_auc_4: 0.9620\n",
      "Epoch 27/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2690 - accuracy: 0.9796 - categorical_accuracy: 0.9796 - categorical_crossentropy: 0.2690 - auc_4: 0.9990 - val_loss: 0.5484 - val_accuracy: 0.8302 - val_categorical_accuracy: 0.8302 - val_categorical_crossentropy: 0.5484 - val_auc_4: 0.9627\n",
      "Epoch 28/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2713 - accuracy: 0.9837 - categorical_accuracy: 0.9837 - categorical_crossentropy: 0.2713 - auc_4: 0.9987 - val_loss: 0.5458 - val_accuracy: 0.8286 - val_categorical_accuracy: 0.8286 - val_categorical_crossentropy: 0.5458 - val_auc_4: 0.9638\n",
      "Epoch 29/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2656 - accuracy: 0.9823 - categorical_accuracy: 0.9823 - categorical_crossentropy: 0.2656 - auc_4: 0.9987 - val_loss: 0.5422 - val_accuracy: 0.8365 - val_categorical_accuracy: 0.8365 - val_categorical_crossentropy: 0.5422 - val_auc_4: 0.9644\n",
      "Epoch 30/30\n",
      "1470/1470 [==============================] - 3s 2ms/step - loss: 0.2755 - accuracy: 0.9803 - categorical_accuracy: 0.9803 - categorical_crossentropy: 0.2755 - auc_4: 0.9992 - val_loss: 0.5444 - val_accuracy: 0.8238 - val_categorical_accuracy: 0.8238 - val_categorical_crossentropy: 0.5444 - val_auc_4: 0.963631 - categorical_accuracy: 0.9831 - categorical_crossentropy: 0.26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21621783d48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the Model\n",
    "#Explanation of the fit arguements\n",
    "#Validation_split splits the training data and uses that split set aside for model validation\n",
    "#in this case we set aside 30% of our training data to be used as validation data and the remaining 70% is used for training\n",
    "#This leaves the original 30% test set as our sample test data. Which will be use on top of the out of sample test data which will be released at a later date\n",
    "#Batch size and epochs are based on parameters set previously\n",
    "#verbose gives us a progress bar per epoch\n",
    "#callbacks includes the learning rate reduction on plateau funtion and stopping the training early if the validation loss plateaus for more than 5 epochs\n",
    "\n",
    "Multiclass_CNN.fit(xTrain, yTrain_OneHot, batch_size= batch_size, epochs= epochs, validation_split= 0.3,  verbose = 1, callbacks = [lrr, ES])\n",
    "#History.history attribute is a record of training loss values and metrics values at successive epochs\n",
    "#as well as validation loss values and validation metrics values (if applicable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Assessing Model Training Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'val_categorical_accuracy', 'val_categorical_crossentropy', 'val_auc_4', 'loss', 'accuracy', 'categorical_accuracy', 'categorical_crossentropy', 'auc_4', 'lr'])\n",
      "Training accuracy:  0.9802721\n",
      "Training loss:  0.2754546740833594\n"
     ]
    }
   ],
   "source": [
    "#Testing addressing of trained model history metrics\n",
    "#Allows us to access the model training history stats such as accuracy in trianing and validation\n",
    "#Shows us the available metrics to check\n",
    "#Can change metrics available by changing metrics to be observed when compiling the model\n",
    "print(Multiclass_CNN.history.history.keys())\n",
    "\n",
    "#Obtains training accuracy and loss of the most recent epoch to be finished\n",
    "acc = Multiclass_CNN.history.history['accuracy'][-1]\n",
    "loss = Multiclass_CNN.history.history['loss'][-1]\n",
    "\n",
    "print(\"Training accuracy: \", acc)\n",
    "print(\"Training loss: \", loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Visualising Model parameters during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2173c415648>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting the Training and validation loss\n",
    "\n",
    "#Creating 2 subsplots under 1 figure\n",
    "f, acc_plot = plt.subplots(2,1)\n",
    "\n",
    "#First subplot graphs training loss and validation loss\n",
    "acc_plot[0].plot(Multiclass_CNN.history.history['loss'], color = 'b', label = 'Training Loss')\n",
    "acc_plot[0].plot(Multiclass_CNN.history.history['val_loss'], color = 'r', label = 'Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "#Second subplot graphs training accuracy and validation accuracy\n",
    "acc_plot[1].plot(Multiclass_CNN.history.history['accuracy'], color = 'b', label = 'Training Accuracy')\n",
    "acc_plot[1].plot(Multiclass_CNN.history.history['val_accuracy'], color = 'r', label = 'Validation Accuracy')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Making Predictions with Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Obtaining Classification report and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 1s 936us/step\n",
      "The Results for Multiclass CNN are:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83       134\n",
      "         1.0       0.81      0.82      0.82       257\n",
      "         2.0       0.78      0.75      0.76       264\n",
      "         3.0       0.90      0.94      0.92       245\n",
      "\n",
      "    accuracy                           0.83       900\n",
      "   macro avg       0.83      0.83      0.83       900\n",
      "weighted avg       0.83      0.83      0.83       900\n",
      "\n",
      "The confusion matrix is:\n",
      "[[111   6  10   7]\n",
      " [  5 211  36   5]\n",
      " [ 15  38 197  14]\n",
      " [  2   4   9 230]]\n"
     ]
    }
   ],
   "source": [
    "#Making Predictions with the model\n",
    "#We make 2 sets of predictions using the trained model. One which predicts the absolute class of the test image \n",
    "#and another subsequently which provides probability of the labels (0 or 1). The latter is used for ROC curve plotting\n",
    "Multiclass_CNN_pred = Multiclass_CNN.predict_classes(xTest, verbose = 1)\n",
    "\n",
    "#Printing the classification report and metrics\n",
    "print(\"The Results for Multiclass CNN are:\")\n",
    "print(classification_report(yTest, Multiclass_CNN_pred))\n",
    "\n",
    "#Printing the confusion matrix for Multiclass CNN\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(yTest, Multiclass_CNN_pred))\n",
    "\n",
    "#To obtain TNR, TPR and FPR metrics for Multiclass CNN in discrete form\n",
    "FPR_Multiclass_CNN, TPR_Multiclass_CNN, Multiclass_CNN_thres = roc_curve(yTest, Multiclass_CNN_pred)\n",
    "#TNR_Multiclass_CNN = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Obtaining ROC curve and other metrics of Multiclass CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_auc_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11500/641314013.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc_auc_score for Binary CNN: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMulticlass_CNN_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_auc_score' is not defined"
     ]
    }
   ],
   "source": [
    "#Printing the main metrics to assess performance of the Multiclass CNN model\n",
    "print(\"The metrics for Multiclass CNN model are as follows\")\n",
    "print(\"True Positive Rate: \", print(TPR_Multiclass_CNN))\n",
    "print(\"True Negative Rate: \", print(TNR_Multiclass_CNN))\n",
    "print('roc_auc_score for Multiclass CNN: ', roc_auc_score(yTest, Multiclass_CNN_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Serialize Multiclass CNN model to json\n",
    "#This saves the model architecture to save space\n",
    "Multiclass_CNN_json = Multiclass_CNN.to_json()\n",
    "with open(\".\\Models\\MultiClassification\\CNN\\Multiclass_CNN.json\", \"w\") as json_file:\n",
    "    json_file.write(Multiclass_CNN_json)\n",
    "\n",
    "#Saving the Multiclass_CNN Model weights \n",
    "Multiclass_CNN.save_weights(\".\\Models\\MultiClassification\\CNN\\Multiclass_CNN_Model_Weights\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#Test to load CNN Model\n",
    "# load Multiclass CNN json and create model\n",
    "json_file = open(\".\\Models\\MultiClassification\\CNN\\Multiclass_CNN.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\".\\Models\\MultiClassification\\CNN\\Multiclass_CNN_Model_Weights\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "290ec9070849e8daf2fe4bd922bd966932468e9fb905fb4b926b0f4d9e51cc32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('gym': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
